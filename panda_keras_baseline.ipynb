{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as albu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.densenet import DenseNet169, DenseNet121\n",
    "import efficientnet.tfkeras as efn\n",
    "from clr import OneCycleLR\n",
    "print('tensorflow version:', tf.__version__)\n",
    "try:\n",
    "    print('available GPU devices:', len(os.environ['CUDA_VISIBLE_DEVICES']), \n",
    "          '| device num:', os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "except:\n",
    "    pass\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_custom_objects\n",
    "class Mish(Activation):\n",
    "    '''\n",
    "    Mish Activation Function.\n",
    "    .. math::\n",
    "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
    "    Shape:\n",
    "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "        - Output: Same shape as the input.\n",
    "    Examples:\n",
    "        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n",
    "    '''\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'Mish'\n",
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
    "get_custom_objects().update({'Mish': Mish(mish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = '.'\n",
    "DATA_PATH = '{}/data'.format(MAIN_PATH)\n",
    "MDL_VERSION = 'v0'\n",
    "MODELS_PATH = '{}/keras_models_{}'.format(MAIN_PATH, MDL_VERSION)\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    os.makedirs(MODELS_PATH)\n",
    "TILES_PATH = '{}/train_images_tiles_q2_128_16'.format(DATA_PATH)\n",
    "IMG_SIZE = 128 #224=B0 240=B1 260=B2 300=B3 380=B4 456=B5\n",
    "SEQ_LEN = 16\n",
    "BATCH_SIZE = 8\n",
    "TIFF = 1\n",
    "RESIZE = None\n",
    "SEED = 80\n",
    "print('96x96x16 size:', 96 * 96 * 16)\n",
    "print('96x96x25 size:', 96 * 96 * 25)\n",
    "print('128x128x12 size:', 128 * 128 * 12)\n",
    "print('154x154x10 size:', 154 * 154 * 10)\n",
    "print('current size:', IMG_SIZE * IMG_SIZE * SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('{}/train.csv'.format(DATA_PATH)).set_index('image_id')\n",
    "print('train: ', train.shape, '| unique ids:', sum(train['isup_grade'].value_counts()))\n",
    "files = sorted(set([x[:32] for x in os.listdir(TILES_PATH) if '.ipynb' not in x]))\n",
    "train = train.loc[files]\n",
    "train = train.reset_index()\n",
    "print('train: ', train.shape, '| unique ids:', sum(train['isup_grade'].value_counts()))\n",
    "train.to_csv('{}/train_dsph.csv'.format(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenPanda(Sequence):\n",
    "    def __init__(self, imgs_path, df, batch_size=32, \n",
    "                 mode='fit', shuffle=False, aug=None,\n",
    "                 tiff=-1, resize=None,\n",
    "                 seq_len=12, img_size=128, n_classes=6):\n",
    "        self.imgs_path = imgs_path\n",
    "        self.df = df\n",
    "        self.shuffle = shuffle\n",
    "        self.mode = mode\n",
    "        self.aug = aug\n",
    "        self.tiff = tiff\n",
    "        self.resize = resize\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.seq_len = seq_len\n",
    "        self.n_classes = n_classes\n",
    "        self.side = int(seq_len ** .5)\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    def __getitem__(self, index):\n",
    "        batch_size = min(self.batch_size, len(self.df) - index * self.batch_size)\n",
    "        X = np.zeros((batch_size, self.side * self.img_size, self.side * self.img_size, 3), dtype=np.float32)\n",
    "        imgs_batch = self.df[index * self.batch_size : (index + 1) * self.batch_size]['image_id'].values\n",
    "        for i, img_name in enumerate(imgs_batch):\n",
    "            img_patches = self.get_patches(img_name)\n",
    "            X[i, ] = self.glue_to_one(img_patches)\n",
    "        if self.mode == 'fit':\n",
    "            y = np.zeros((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "            #y = np.zeros(self.batch_size, dtype=np.float32)\n",
    "            lbls_batch = self.df[index * self.batch_size : (index + 1) * self.batch_size]['isup_grade'].values\n",
    "            for i in range(self.batch_size):\n",
    "                y[i, lbls_batch[i]] = 1\n",
    "                #y[i, ] = lbls_batch[i]\n",
    "            return X, y\n",
    "        elif self.mode == 'predict':\n",
    "            return X\n",
    "        else:\n",
    "            raise AttributeError('mode parameter error')\n",
    "    def get_patches(self, img_name):\n",
    "        seq_imgs = []\n",
    "        for i in range(self.seq_len):\n",
    "            img_path = '{}/{}_{}.png'.format(self.imgs_path, img_name, i)\n",
    "            img = cv2.imread(img_path)\n",
    "            if not np.any(img):\n",
    "                print(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            if self.resize:\n",
    "                img = cv2.resize(img, (int(img.shape[1] / self.resize), int(img.shape[0] / self.resize)))\n",
    "            img = img.astype(np.float32) / 255\n",
    "            if self.aug:\n",
    "                img = self.aug(image=img)['image']\n",
    "            seq_imgs.append(img)\n",
    "        return np.array(seq_imgs).astype(np.float32)\n",
    "    def glue_to_one(self, imgs_seq):\n",
    "        img_glue = np.zeros((self.img_size * self.side, self.img_size * self.side, 3), dtype=np.float32)\n",
    "        for i, ptch in enumerate(imgs_seq):\n",
    "            x = i // self.side\n",
    "            y = i % self.side\n",
    "            img_glue[x * self.img_size : (x + 1) * self.img_size, \n",
    "                     y * self.img_size : (y + 1) * self.img_size, :] = ptch\n",
    "        return img_glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=.2, stratify=train['isup_grade'], random_state=SEED)\n",
    "lbl_value_counts = X_train['isup_grade'].value_counts()\n",
    "class_weights = {i: max(lbl_value_counts) / v for i, v in lbl_value_counts.items()}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = albu.Compose(\n",
    "    [\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomBrightness(limit=.15), \n",
    "                albu.RandomContrast(limit=.3), \n",
    "                albu.RandomGamma()\n",
    "            ], \n",
    "            p=.3\n",
    "        ),\n",
    "        albu.HorizontalFlip(p=.3),\n",
    "        albu.VerticalFlip(p=.3),\n",
    "        albu.ShiftScaleRotate(shift_limit=.2, scale_limit=.2, rotate_limit=30, p=.3)\n",
    "    ]\n",
    ")\n",
    "train_datagen = DataGenPanda(\n",
    "    imgs_path=TILES_PATH, \n",
    "    df=X_train, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode='fit', \n",
    "    shuffle=True, \n",
    "    aug=aug, \n",
    "    tiff=TIFF,\n",
    "    resize=RESIZE,\n",
    "    seq_len=SEQ_LEN, \n",
    "    img_size=IMG_SIZE, \n",
    "    n_classes=6\n",
    ")\n",
    "val_datagen = DataGenPanda(\n",
    "    imgs_path=TILES_PATH, \n",
    "    df=X_val, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    mode='fit', \n",
    "    shuffle=False, \n",
    "    aug=None,\n",
    "    tiff=TIFF,\n",
    "    resize=RESIZE,\n",
    "    seq_len=SEQ_LEN, \n",
    "    img_size=IMG_SIZE, \n",
    "    n_classes=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Xt, yt = train_datagen.__getitem__(0)\n",
    "print('test X: ', Xt.shape)\n",
    "print('test y: ', yt.shape)\n",
    "fig, axes = plt.subplots(figsize=(10, 6), ncols=BATCH_SIZE)\n",
    "for j in range(BATCH_SIZE):\n",
    "    axes[j].imshow(Xt[j])\n",
    "    axes[j].axis('off')\n",
    "    axes[j].set_title(np.argmax(yt[j, ]))\n",
    "plt.show()\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qw_kappa_score(y_true, y_pred):\n",
    "    y_true=tf.math.argmax(y_true, axis=1)\n",
    "    y_pred=tf.math.argmax(y_pred, axis=1)\n",
    "    def sklearn_qwk(y_true, y_pred) -> np.float64:\n",
    "        return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    return tf.compat.v1.py_func(sklearn_qwk, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck = efn.EfficientNetB0(\n",
    "    input_shape=(int(SEQ_LEN ** .5) * IMG_SIZE, int(SEQ_LEN ** .5) * IMG_SIZE, 3),\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    pooling='avg'\n",
    ")\n",
    "bottleneck = Model(inputs=bottleneck.inputs, outputs=bottleneck.layers[-2].output)\n",
    "model = Sequential()\n",
    "model.add(bottleneck)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(512, activation='Mish'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(128, activation='Mish'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(.4))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(lr=1e-2), # epsilon=1e-4 for float16 numerical stability\n",
    "    metrics=['categorical_accuracy', qw_kappa_score]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_file = '{}/model_{}.h5'.format(MODELS_PATH, MDL_VERSION)\n",
    "if False:\n",
    "    model = load_model(model_file)\n",
    "    print('model loaded')\n",
    "else:\n",
    "    print('train from scratch')\n",
    "EPOCHS = 40\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_qw_kappa_score', \n",
    "    patience=20, \n",
    "    verbose=1,\n",
    "    mode='max'\n",
    ")\n",
    "modelsaver = ModelCheckpoint(\n",
    "    model_file, \n",
    "    monitor='val_qw_kappa_score', \n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "lrreducer = ReduceLROnPlateau(\n",
    "    monitor='val_qw_kappa_score',\n",
    "    factor=.1,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    min_lr=3e-7\n",
    ")\n",
    "lrmanager = OneCycleLR(\n",
    "    max_lr=1e-2,\n",
    "    end_percentage=0.1, \n",
    "    scale_percentage=None,\n",
    "    maximum_momentum=0.95, \n",
    "    minimum_momentum=0.85\n",
    ")\n",
    "history = model.fit_generator(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[earlystopper, modelsaver, lrmanager],\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_file = '{}/history_{}.txt'.format(MODELS_PATH, MDL_VERSION)\n",
    "dict_to_save = {}\n",
    "for k, v in history.history.items():\n",
    "    dict_to_save.update({k: [np.format_float_positional(x) for x in history.history[k]]})\n",
    "with open(history_file, 'w') as file:\n",
    "    json.dump(dict_to_save, file)\n",
    "ep_max = EPOCHS\n",
    "plt.plot(history.history['loss'][:ep_max], label='loss')\n",
    "plt.plot(history.history['val_loss'][:ep_max], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history['categorical_accuracy'][:ep_max], label='cat acc')\n",
    "plt.plot(history.history['val_categorical_accuracy'][:ep_max], label='val cat acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history['qw_kappa_score'][:ep_max], label='qwk')\n",
    "plt.plot(history.history['val_qw_kappa_score'][:ep_max], label='val qwk')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_file = '{}/model_{}.h5'.format(MODELS_PATH, MDL_VERSION)\n",
    "model = load_model(model_file)\n",
    "print('model loaded:', model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_score = X_val.copy()\n",
    "val_datagen = DataGenPanda(\n",
    "    imgs_path=TILES_PATH, \n",
    "    df=X_score, \n",
    "    batch_size=1,\n",
    "    mode='predict', \n",
    "    shuffle=False, \n",
    "    aug=None,\n",
    "    tiff=TIFF,\n",
    "    resize=RESIZE,\n",
    "    seq_len=SEQ_LEN, \n",
    "    img_size=IMG_SIZE, \n",
    "    n_classes=6\n",
    ")\n",
    "preds = model.predict_generator(val_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = X_score['isup_grade'].values\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print('quadratic cappa score:', cohen_kappa_score(y_true, y_pred, weights='quadratic'))\n",
    "print('confusion matrix:\\n', confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
