{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.61\n",
      "0 Graphics Device\n",
      "  allocated: 0.0 GB\n",
      "  cached:    0.0 GB\n",
      "1 Graphics Device\n",
      "  allocated: 0.0 GB\n",
      "  cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, './fastai_utils/')\n",
    "from radam import *\n",
    "from csvlogger import *\n",
    "from mish_activation import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(fastai.__version__)\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))\n",
    "    print('  allocated:', round(torch.cuda.memory_allocated(i) / 1024 ** 3, 1), 'GB')\n",
    "    print('  cached:   ', round(torch.cuda.memory_cached(i) / 1024 ** 3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256x256x18 img size: 1179648\n",
      "128x128x32 img size: 524288\n",
      "current img size: 1310720\n"
     ]
    }
   ],
   "source": [
    "sz = 256\n",
    "bs = 8\n",
    "nfolds = 4\n",
    "SEED = 80\n",
    "N_WORKERS = 8\n",
    "N = 20\n",
    "MODEL_VER = 'v14'\n",
    "MAIN_PATH = '.'\n",
    "DATA_PATH = '{}/data'.format(MAIN_PATH)\n",
    "TRAIN = '{}/train_images_tiles_q1_256_36/'.format(DATA_PATH)\n",
    "LABELS = '{}/train.csv'.format(DATA_PATH)\n",
    "MODELS = '{}/fastai_models'.format(MAIN_PATH)\n",
    "if not os.path.exists('{}_{}'.format(MODELS, MODEL_VER)):\n",
    "    os.mkdir('{}_{}'.format(MODELS, MODEL_VER))\n",
    "    print('created:', '{}_{}'.format(MODELS, MODEL_VER))\n",
    "# v_ = sz 256 bs 6 N 12 folds 4 --> 0.8398 (1st fold)\n",
    "# v0 = sz 256 bs 8 N 8  folds 4 --> 0.8057 (1st fold)\n",
    "# v1 = sz 512 bs 6 N 3 folds 4 --> 0.7959 (1st fold)\n",
    "# v2 = sz 256 bs 5 N 14 folds 4 max_lr 1e-3 df 1000 --> .77998 (1st fold)\n",
    "# v3 = sz 256 bs 6 N 12 folds 4 max_lr 1e-3 df 1000 --> \n",
    "# v4 = sz 256_36 bs 6 N 12 folds 4 max_lr 3e-4 df 100 --> .8382(0), .8234(1), .8392(2), .8251(2), .8314(all) --> .84 LB\n",
    "# v5 = sz 256_36 bs 6 N 12 folds 4 max_lr 5e-4 df 500 ep 40 --> .8341 (1st fold)\n",
    "# v6 = sz 128_24_r2 bs 12 N 24 folds 4 max_lr 3e-4 df 100 ep 30 --> .8400 (1st fold)\n",
    "# v7 = sz 128_32 bs 8 N 32 folds 4 max_lr 3e-4 df 100 ep 30 --> .8422(0) .8380(1) .8423(2) .8340(3) .8391(all) --> .85 LB\n",
    "# v8 = sz 256_36 bs 12(x2) N 12 folds 4 max_lr 3e-4 df 100 --> .8400(0)\n",
    "# v9 = sz 256_36 bs 6(x2) N 22 folds 4 max_lr 3e-4 df 100 ep 30 --> .8264(0)\n",
    "# v10 = sz 256_36 bs 8(x2) N 18 folds 4 max_lr 3e-4 df 100 ep 30 --> .8510(0)\n",
    "# v11 = sz 156_64 bs 8(x2) N 48 folds 4 max_lr 3e-4 df 100 ep 30 --> .8527(0)\n",
    "# v12 = sz 156_64 bs 12(x2) N 36 folds 4 max_lr 3e-4 df 100 ep 30 --> .8423(0)\n",
    "# v13 = sz 156_64 bs 12(x2) N 54 folds 4 max_lr 3e-4 df 100 ep 40 --> .8493(0)\n",
    "# v14 =  sz 256_36 bs 8(x2) N 20 folds 4 max_lr 3e-4 df 100 ep 40--> .8626(0) .8513(1) .8539(2) .8547(3) .8556(all)\n",
    "print('256x256x18 img size:', 256 * 256 * 18)\n",
    "print('128x128x32 img size:', 128 * 128 * 32)\n",
    "print('current img size:', sz * sz * N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4   \n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0   \n",
       "\n",
       "   split  \n",
       "0      1  \n",
       "1      2  \n",
       "2      0  \n",
       "3      3  \n",
       "4      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(LABELS).set_index('image_id')\n",
    "files = sorted(set([p[:32] for p in os.listdir(TRAIN) if '.ipynb' not in p]))\n",
    "df = df.loc[files]\n",
    "df = df.reset_index()\n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True)\n",
    "splits = list(splits.split(df,df.isup_grade))\n",
    "folds_splits = np.zeros(len(df)).astype(np.int)\n",
    "for i in range(nfolds): folds_splits[splits[i][1]] = i\n",
    "df['split'] = folds_splits\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q1_256_36\n",
    "mean = torch.tensor([1 - .85506157, 1 - .7035249, 1 - .80203127])\n",
    "std = torch.tensor([.40011922, .52504386, .42675745])\n",
    "# q1_512_16\n",
    "#mean = torch.tensor([1 - .91066496, 1 - .82012713, 1 - .87912669])\n",
    "#std = torch.tensor([.37697129, .50629405, .41176592])\n",
    "# q1_256_24\n",
    "#mean = torch.tensor([1 - .82934477, 1 - .64875879, 1 - .76593138])\n",
    "#std = torch.tensor([.40447862, .51985678, .42330205])\n",
    "# q1_128_32\n",
    "#mean = torch.tensor([1 - .75793065, 1 - .5088926, 1 - .67191824])\n",
    "#std = torch.tensor([.41296871, .47099853, .39308129])\n",
    "# q1_128_24_r2\n",
    "#mean = torch.tensor([1 - .8296201, 1 - .64903966, 1 - .76621777])\n",
    "#std = torch.tensor([.39454631, .51460749, .41747009])\n",
    "# q1_156_64\n",
    "#mean = torch.tensor([1 - .81198481, 1 - .61055975, 1 - .74127657])\n",
    "#std = torch.tensor([.40365266, .50938881, .41515295])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(fn:PathOrStr, div:bool=True, convert_mode:str='RGB', cls:type=Image,\n",
    "        after_open:Callable=None)->Image:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        x = PIL.Image.open(fn).convert(convert_mode)\n",
    "    if after_open: x = after_open(x)\n",
    "    x = pil2tensor(x,np.float32)\n",
    "    if div: x.div_(255)\n",
    "    return cls(1.0-x) #invert image for zero padding\n",
    "class MImage(ItemBase):\n",
    "    def __init__(self, imgs):\n",
    "        self.obj, self.data = \\\n",
    "          (imgs), [(imgs[i].data - mean[...,None,None])/std[...,None,None] for i in range(len(imgs))]\n",
    "    def apply_tfms(self, tfms,*args, **kwargs):\n",
    "        for i in range(len(self.obj)):\n",
    "            self.obj[i] = self.obj[i].apply_tfms(tfms, *args, **kwargs)\n",
    "            self.data[i] = (self.obj[i].data - mean[...,None,None])/std[...,None,None]\n",
    "        return self\n",
    "    def __repr__(self): return f'{self.__class__.__name__} {img.shape for img in self.obj}'\n",
    "    def to_one(self):\n",
    "        img = torch.stack(self.data,1)\n",
    "        img = img.view(3,-1,N,sz,sz).permute(0,1,3,2,4).contiguous().view(3,-1,sz*N)\n",
    "        return Image(1.0 - (mean[...,None,None]+img*std[...,None,None]))\n",
    "class MImageItemList(ImageList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def __len__(self)->int: return len(self.items) or 1 \n",
    "    def get(self, i):\n",
    "        fn = Path(self.items[i])\n",
    "        fnames = [Path(str(fn)+'_'+str(i)+'.png')for i in range(N)]\n",
    "        imgs = [open_image(fname, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "               for fname in fnames]\n",
    "        return MImage(imgs)\n",
    "    def reconstruct(self, t):\n",
    "        return MImage([mean[...,None,None]+_t*std[...,None,None] for _t in t])\n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(300,50), **kwargs):\n",
    "        rows = min(len(xs),8)\n",
    "        fig, axs = plt.subplots(rows,1,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            xs[i].to_one().show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()\n",
    "def MImage_collate(batch:ItemsList)->Tensor:\n",
    "    result = torch.utils.data.dataloader.default_collate(to_data(batch))\n",
    "    if isinstance(result[0],list):\n",
    "        result = [torch.stack(result[0],1),result[1]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fold=0):\n",
    "    return (\n",
    "        MImageItemList.from_df(df, path='.', folder=TRAIN, cols='image_id')\n",
    "        .split_by_idx(df.index[df.split == fold].tolist())\n",
    "        .label_from_df(cols=['isup_grade'])\n",
    "        .transform(\n",
    "            get_transforms(\n",
    "                flip_vert=True,\n",
    "                max_rotate=15,\n",
    "                max_warp=None\n",
    "            ),\n",
    "            size=sz,\n",
    "            padding_mode='zeros'\n",
    "        ).databunch(\n",
    "            bs=bs, \n",
    "            num_workers=N_WORKERS\n",
    "        )\n",
    "    )\n",
    "data = get_data(0)\n",
    "#data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "        super().__init__()\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        self.enc = nn.DataParallel(nn.Sequential(*list(m.children())[:-2]))\n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.DataParallel(nn.Sequential(\n",
    "            AdaptiveConcatPool2d(),\n",
    "            Flatten(),\n",
    "            nn.Linear(2 * nc, 512),\n",
    "            Mish(),\n",
    "            nn.BatchNorm1d(512), \n",
    "            nn.Dropout(.4),\n",
    "            nn.Linear(512, n)\n",
    "        ))\n",
    "    def forward(self, *x):\n",
    "        shape = x[0].shape\n",
    "        n = len(x)\n",
    "        x = torch.stack(x,1).view(\n",
    "            -1,\n",
    "            shape[1],\n",
    "            shape[2],\n",
    "            shape[3]\n",
    "        )\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x = x.view(\n",
    "            -1,\n",
    "            n,\n",
    "            shape[1],\n",
    "            shape[2],\n",
    "            shape[3]\n",
    "        ).permute(0, 2, 1, 3, 4).contiguous().view(\n",
    "            -1,\n",
    "            shape[1],\n",
    "            shape[2] * n,\n",
    "            shape[3]\n",
    "        )\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- fold: 0 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /u01/mrorange/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.349970</td>\n",
       "      <td>1.123420</td>\n",
       "      <td>0.723867</td>\n",
       "      <td>16:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.400526</td>\n",
       "      <td>1.087826</td>\n",
       "      <td>0.745991</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.349426</td>\n",
       "      <td>1.224559</td>\n",
       "      <td>0.759278</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.252211</td>\n",
       "      <td>1.053766</td>\n",
       "      <td>0.682915</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.183372</td>\n",
       "      <td>1.224531</td>\n",
       "      <td>0.626279</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.150523</td>\n",
       "      <td>0.957378</td>\n",
       "      <td>0.791645</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.178163</td>\n",
       "      <td>0.964952</td>\n",
       "      <td>0.795631</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.201370</td>\n",
       "      <td>1.052269</td>\n",
       "      <td>0.623135</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.182096</td>\n",
       "      <td>1.051901</td>\n",
       "      <td>0.735533</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.110160</td>\n",
       "      <td>1.068828</td>\n",
       "      <td>0.770932</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.091069</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.740312</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.130872</td>\n",
       "      <td>0.939633</td>\n",
       "      <td>0.797001</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.106754</td>\n",
       "      <td>0.895155</td>\n",
       "      <td>0.806366</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.135746</td>\n",
       "      <td>1.017977</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.058346</td>\n",
       "      <td>1.047570</td>\n",
       "      <td>0.771947</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.097602</td>\n",
       "      <td>0.935130</td>\n",
       "      <td>0.777378</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.066728</td>\n",
       "      <td>0.919974</td>\n",
       "      <td>0.794136</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.982241</td>\n",
       "      <td>0.917235</td>\n",
       "      <td>0.825419</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.967617</td>\n",
       "      <td>0.867304</td>\n",
       "      <td>0.825776</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.973374</td>\n",
       "      <td>0.947194</td>\n",
       "      <td>0.781215</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.983125</td>\n",
       "      <td>0.906503</td>\n",
       "      <td>0.805070</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.895815</td>\n",
       "      <td>0.850942</td>\n",
       "      <td>0.820006</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.921307</td>\n",
       "      <td>0.831709</td>\n",
       "      <td>0.824667</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.917937</td>\n",
       "      <td>0.850156</td>\n",
       "      <td>0.830883</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.850576</td>\n",
       "      <td>0.856029</td>\n",
       "      <td>0.814950</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.976926</td>\n",
       "      <td>0.854138</td>\n",
       "      <td>0.840890</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.844190</td>\n",
       "      <td>0.876526</td>\n",
       "      <td>0.832234</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.842479</td>\n",
       "      <td>0.806873</td>\n",
       "      <td>0.846977</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.856763</td>\n",
       "      <td>0.799817</td>\n",
       "      <td>0.833982</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.839711</td>\n",
       "      <td>0.825320</td>\n",
       "      <td>0.846786</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.836250</td>\n",
       "      <td>0.825110</td>\n",
       "      <td>0.838214</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.828616</td>\n",
       "      <td>0.790934</td>\n",
       "      <td>0.855931</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.737267</td>\n",
       "      <td>0.790891</td>\n",
       "      <td>0.861353</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.795038</td>\n",
       "      <td>0.808460</td>\n",
       "      <td>0.844889</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.841091</td>\n",
       "      <td>0.801201</td>\n",
       "      <td>0.859220</td>\n",
       "      <td>16:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.737114</td>\n",
       "      <td>0.800347</td>\n",
       "      <td>0.855799</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.790036</td>\n",
       "      <td>0.817537</td>\n",
       "      <td>0.862668</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.753417</td>\n",
       "      <td>0.783798</td>\n",
       "      <td>0.857137</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.792263</td>\n",
       "      <td>0.799014</td>\n",
       "      <td>0.855273</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.815142</td>\n",
       "      <td>0.851726</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.7238669395446777.\n",
      "Better model found at epoch 1 with kappa_score value: 0.7459914684295654.\n",
      "Better model found at epoch 2 with kappa_score value: 0.7592782974243164.\n",
      "Better model found at epoch 5 with kappa_score value: 0.791645348072052.\n",
      "Better model found at epoch 6 with kappa_score value: 0.7956308126449585.\n",
      "Better model found at epoch 11 with kappa_score value: 0.7970012426376343.\n",
      "Better model found at epoch 12 with kappa_score value: 0.8063660264015198.\n",
      "Better model found at epoch 17 with kappa_score value: 0.8254194259643555.\n",
      "Better model found at epoch 18 with kappa_score value: 0.8257757425308228.\n",
      "Better model found at epoch 23 with kappa_score value: 0.8308830261230469.\n",
      "Better model found at epoch 25 with kappa_score value: 0.8408898115158081.\n",
      "Better model found at epoch 27 with kappa_score value: 0.8469771146774292.\n",
      "Better model found at epoch 31 with kappa_score value: 0.8559314012527466.\n",
      "Better model found at epoch 32 with kappa_score value: 0.8613529205322266.\n",
      "Better model found at epoch 36 with kappa_score value: 0.8626682162284851.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='329' class='' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [329/329 01:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8626681978895994\n",
      "[[685  29   2   0   3   0]\n",
      " [ 62 528  47   6  10   1]\n",
      " [  9 103 145  59  17   2]\n",
      " [ 21  15  29 145  69  27]\n",
      " [ 19  11   8  36 201  36]\n",
      " [ 12   4   4  24  81 179]]\n",
      "-------------------- fold: 1 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /u01/mrorange/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.471360</td>\n",
       "      <td>1.160802</td>\n",
       "      <td>0.662466</td>\n",
       "      <td>16:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.344752</td>\n",
       "      <td>1.097230</td>\n",
       "      <td>0.750691</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.238598</td>\n",
       "      <td>1.115645</td>\n",
       "      <td>0.654876</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.274899</td>\n",
       "      <td>1.171538</td>\n",
       "      <td>0.711890</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.200997</td>\n",
       "      <td>1.216931</td>\n",
       "      <td>0.632323</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.285302</td>\n",
       "      <td>1.162653</td>\n",
       "      <td>0.707284</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.244746</td>\n",
       "      <td>1.022574</td>\n",
       "      <td>0.741862</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.205214</td>\n",
       "      <td>1.041937</td>\n",
       "      <td>0.743284</td>\n",
       "      <td>16:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.165881</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>0.658961</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.121707</td>\n",
       "      <td>0.994082</td>\n",
       "      <td>0.719026</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.092219</td>\n",
       "      <td>1.184445</td>\n",
       "      <td>0.684011</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.102597</td>\n",
       "      <td>1.127101</td>\n",
       "      <td>0.645482</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.114638</td>\n",
       "      <td>0.936897</td>\n",
       "      <td>0.785261</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.081766</td>\n",
       "      <td>1.016214</td>\n",
       "      <td>0.723292</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.082647</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>0.808536</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.025509</td>\n",
       "      <td>0.934428</td>\n",
       "      <td>0.802262</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.095533</td>\n",
       "      <td>1.053980</td>\n",
       "      <td>0.734717</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.029052</td>\n",
       "      <td>0.937199</td>\n",
       "      <td>0.784656</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.953479</td>\n",
       "      <td>0.913230</td>\n",
       "      <td>0.821968</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.966288</td>\n",
       "      <td>0.869056</td>\n",
       "      <td>0.820361</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.989286</td>\n",
       "      <td>0.949870</td>\n",
       "      <td>0.760967</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.023525</td>\n",
       "      <td>1.003144</td>\n",
       "      <td>0.733603</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.986870</td>\n",
       "      <td>0.985806</td>\n",
       "      <td>0.789795</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.949362</td>\n",
       "      <td>0.851835</td>\n",
       "      <td>0.839395</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.902503</td>\n",
       "      <td>0.855478</td>\n",
       "      <td>0.812448</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.829729</td>\n",
       "      <td>0.837430</td>\n",
       "      <td>0.823423</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.840965</td>\n",
       "      <td>0.807665</td>\n",
       "      <td>0.842348</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.926252</td>\n",
       "      <td>0.875657</td>\n",
       "      <td>0.817077</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.935038</td>\n",
       "      <td>0.803857</td>\n",
       "      <td>0.838899</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.861523</td>\n",
       "      <td>0.802121</td>\n",
       "      <td>0.848023</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.817264</td>\n",
       "      <td>0.790415</td>\n",
       "      <td>0.851311</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.781555</td>\n",
       "      <td>0.815633</td>\n",
       "      <td>0.825011</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.779524</td>\n",
       "      <td>0.792010</td>\n",
       "      <td>0.837382</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.810676</td>\n",
       "      <td>0.797065</td>\n",
       "      <td>0.846444</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.794140</td>\n",
       "      <td>0.786024</td>\n",
       "      <td>0.846806</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.727838</td>\n",
       "      <td>0.803303</td>\n",
       "      <td>0.841361</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.789485</td>\n",
       "      <td>0.811858</td>\n",
       "      <td>0.838571</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.781418</td>\n",
       "      <td>0.800252</td>\n",
       "      <td>0.836849</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.743327</td>\n",
       "      <td>0.795137</td>\n",
       "      <td>0.843802</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.817475</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.843477</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.6624659299850464.\n",
      "Better model found at epoch 1 with kappa_score value: 0.7506911754608154.\n",
      "Better model found at epoch 12 with kappa_score value: 0.7852610945701599.\n",
      "Better model found at epoch 14 with kappa_score value: 0.8085359930992126.\n",
      "Better model found at epoch 18 with kappa_score value: 0.8219678997993469.\n",
      "Better model found at epoch 23 with kappa_score value: 0.8393949270248413.\n",
      "Better model found at epoch 26 with kappa_score value: 0.8423477411270142.\n",
      "Better model found at epoch 29 with kappa_score value: 0.8480232357978821.\n",
      "Better model found at epoch 30 with kappa_score value: 0.8513107299804688.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='329' class='' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [329/329 01:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8513107185128672\n",
      "[[691  23   0   2   2   0]\n",
      " [ 63 533  52   2   4   0]\n",
      " [  9 102 167  37  16   4]\n",
      " [ 16  19  44 143  54  30]\n",
      " [ 14  18  13  55 177  35]\n",
      " [ 22   1   6  32  68 175]]\n",
      "-------------------- fold: 2 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /u01/mrorange/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.406057</td>\n",
       "      <td>1.256878</td>\n",
       "      <td>0.707485</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.374501</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.720635</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.302506</td>\n",
       "      <td>1.146176</td>\n",
       "      <td>0.723507</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.241321</td>\n",
       "      <td>1.404906</td>\n",
       "      <td>0.537552</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.163788</td>\n",
       "      <td>1.043441</td>\n",
       "      <td>0.758344</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.246155</td>\n",
       "      <td>1.154116</td>\n",
       "      <td>0.663750</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.198473</td>\n",
       "      <td>1.215240</td>\n",
       "      <td>0.749373</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.228685</td>\n",
       "      <td>1.183070</td>\n",
       "      <td>0.726055</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.150227</td>\n",
       "      <td>1.006977</td>\n",
       "      <td>0.765724</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.193677</td>\n",
       "      <td>0.971678</td>\n",
       "      <td>0.769706</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.138602</td>\n",
       "      <td>1.081500</td>\n",
       "      <td>0.784693</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.119564</td>\n",
       "      <td>0.938391</td>\n",
       "      <td>0.817946</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.103665</td>\n",
       "      <td>0.963209</td>\n",
       "      <td>0.776430</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.051022</td>\n",
       "      <td>0.910384</td>\n",
       "      <td>0.801356</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.009187</td>\n",
       "      <td>0.905184</td>\n",
       "      <td>0.815220</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.997303</td>\n",
       "      <td>0.928450</td>\n",
       "      <td>0.789346</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.034455</td>\n",
       "      <td>0.980758</td>\n",
       "      <td>0.792879</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.072343</td>\n",
       "      <td>0.870320</td>\n",
       "      <td>0.832052</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.994388</td>\n",
       "      <td>0.894198</td>\n",
       "      <td>0.821230</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.015911</td>\n",
       "      <td>0.888892</td>\n",
       "      <td>0.832984</td>\n",
       "      <td>16:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.940887</td>\n",
       "      <td>0.926498</td>\n",
       "      <td>0.816306</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.966260</td>\n",
       "      <td>0.902626</td>\n",
       "      <td>0.796755</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.927212</td>\n",
       "      <td>0.905531</td>\n",
       "      <td>0.830231</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.929438</td>\n",
       "      <td>0.837576</td>\n",
       "      <td>0.847779</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.906197</td>\n",
       "      <td>0.824106</td>\n",
       "      <td>0.851196</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.877659</td>\n",
       "      <td>0.889935</td>\n",
       "      <td>0.805098</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.882427</td>\n",
       "      <td>0.849613</td>\n",
       "      <td>0.816893</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.861144</td>\n",
       "      <td>0.825943</td>\n",
       "      <td>0.840682</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.904633</td>\n",
       "      <td>0.821485</td>\n",
       "      <td>0.837379</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.844295</td>\n",
       "      <td>0.823086</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.855958</td>\n",
       "      <td>0.813223</td>\n",
       "      <td>0.853923</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.849361</td>\n",
       "      <td>0.824123</td>\n",
       "      <td>0.847220</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.775582</td>\n",
       "      <td>0.794015</td>\n",
       "      <td>0.848887</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.789974</td>\n",
       "      <td>0.813443</td>\n",
       "      <td>0.845991</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.753862</td>\n",
       "      <td>0.805942</td>\n",
       "      <td>0.845456</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.769862</td>\n",
       "      <td>0.807367</td>\n",
       "      <td>0.847907</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.810017</td>\n",
       "      <td>0.807453</td>\n",
       "      <td>0.845624</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.758973</td>\n",
       "      <td>0.805449</td>\n",
       "      <td>0.849686</td>\n",
       "      <td>16:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.822583</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>0.839987</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.825253</td>\n",
       "      <td>0.841809</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.7074849605560303.\n",
      "Better model found at epoch 1 with kappa_score value: 0.7206354141235352.\n",
      "Better model found at epoch 2 with kappa_score value: 0.7235074043273926.\n",
      "Better model found at epoch 4 with kappa_score value: 0.7583444118499756.\n",
      "Better model found at epoch 8 with kappa_score value: 0.7657241821289062.\n",
      "Better model found at epoch 9 with kappa_score value: 0.7697063684463501.\n",
      "Better model found at epoch 10 with kappa_score value: 0.7846934199333191.\n",
      "Better model found at epoch 11 with kappa_score value: 0.8179455995559692.\n",
      "Better model found at epoch 17 with kappa_score value: 0.8320522308349609.\n",
      "Better model found at epoch 19 with kappa_score value: 0.8329839706420898.\n",
      "Better model found at epoch 23 with kappa_score value: 0.8477786779403687.\n",
      "Better model found at epoch 24 with kappa_score value: 0.8511955738067627.\n",
      "Better model found at epoch 30 with kappa_score value: 0.8539228439331055.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='329' class='' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [329/329 01:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8539228367504973\n",
      "[[676  37   1   0   3   1]\n",
      " [ 62 522  58   4   7   1]\n",
      " [ 15  89 150  61  16   4]\n",
      " [ 17  23  37 134  69  27]\n",
      " [ 19  11  13  48 180  40]\n",
      " [ 15   3   1  29  81 175]]\n",
      "-------------------- fold: 3 --------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /u01/mrorange/.cache/torch/hub/facebookresearch_semi-supervised-ImageNet1K-models_master\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.491646</td>\n",
       "      <td>1.199876</td>\n",
       "      <td>0.699800</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.296882</td>\n",
       "      <td>1.196307</td>\n",
       "      <td>0.675721</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.302471</td>\n",
       "      <td>1.598838</td>\n",
       "      <td>0.644009</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.242595</td>\n",
       "      <td>1.021652</td>\n",
       "      <td>0.763110</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.235247</td>\n",
       "      <td>1.039450</td>\n",
       "      <td>0.743286</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.232638</td>\n",
       "      <td>0.978703</td>\n",
       "      <td>0.761300</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.107760</td>\n",
       "      <td>1.001514</td>\n",
       "      <td>0.744476</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.132136</td>\n",
       "      <td>1.167315</td>\n",
       "      <td>0.704356</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.194473</td>\n",
       "      <td>1.005017</td>\n",
       "      <td>0.757321</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.158311</td>\n",
       "      <td>0.950148</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.132968</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>0.713522</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.106458</td>\n",
       "      <td>0.959376</td>\n",
       "      <td>0.773889</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.090986</td>\n",
       "      <td>0.962053</td>\n",
       "      <td>0.770766</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.101004</td>\n",
       "      <td>0.951463</td>\n",
       "      <td>0.795810</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.135643</td>\n",
       "      <td>0.921165</td>\n",
       "      <td>0.776908</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.039178</td>\n",
       "      <td>0.927179</td>\n",
       "      <td>0.803034</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.049810</td>\n",
       "      <td>0.869345</td>\n",
       "      <td>0.810822</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.884296</td>\n",
       "      <td>0.805567</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.960361</td>\n",
       "      <td>0.879552</td>\n",
       "      <td>0.824304</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.994204</td>\n",
       "      <td>0.883298</td>\n",
       "      <td>0.814282</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.042490</td>\n",
       "      <td>0.848311</td>\n",
       "      <td>0.837189</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.928174</td>\n",
       "      <td>0.876027</td>\n",
       "      <td>0.814312</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.883185</td>\n",
       "      <td>0.838636</td>\n",
       "      <td>0.813217</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.912696</td>\n",
       "      <td>0.829567</td>\n",
       "      <td>0.828762</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.863206</td>\n",
       "      <td>0.813116</td>\n",
       "      <td>0.826566</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.887660</td>\n",
       "      <td>0.811822</td>\n",
       "      <td>0.829267</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.917134</td>\n",
       "      <td>0.808978</td>\n",
       "      <td>0.839804</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.880643</td>\n",
       "      <td>0.799752</td>\n",
       "      <td>0.842596</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.841772</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.818823</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.800451</td>\n",
       "      <td>0.818442</td>\n",
       "      <td>0.843316</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.851365</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.850006</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.802552</td>\n",
       "      <td>0.807360</td>\n",
       "      <td>0.831563</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.791499</td>\n",
       "      <td>0.788896</td>\n",
       "      <td>0.846886</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.778537</td>\n",
       "      <td>0.775492</td>\n",
       "      <td>0.854729</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.820287</td>\n",
       "      <td>0.773198</td>\n",
       "      <td>0.841851</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.851380</td>\n",
       "      <td>0.760237</td>\n",
       "      <td>0.842890</td>\n",
       "      <td>16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.798865</td>\n",
       "      <td>0.785222</td>\n",
       "      <td>0.847069</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.818854</td>\n",
       "      <td>0.781706</td>\n",
       "      <td>0.854245</td>\n",
       "      <td>16:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.713066</td>\n",
       "      <td>0.769390</td>\n",
       "      <td>0.852822</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.820803</td>\n",
       "      <td>0.763147</td>\n",
       "      <td>0.849049</td>\n",
       "      <td>16:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with kappa_score value: 0.6997998952865601.\n",
      "Better model found at epoch 3 with kappa_score value: 0.7631097435951233.\n",
      "Better model found at epoch 9 with kappa_score value: 0.7854011654853821.\n",
      "Better model found at epoch 13 with kappa_score value: 0.7958096861839294.\n",
      "Better model found at epoch 15 with kappa_score value: 0.8030343055725098.\n",
      "Better model found at epoch 16 with kappa_score value: 0.8108221888542175.\n",
      "Better model found at epoch 18 with kappa_score value: 0.8243037462234497.\n",
      "Better model found at epoch 20 with kappa_score value: 0.837189257144928.\n",
      "Better model found at epoch 26 with kappa_score value: 0.8398044109344482.\n",
      "Better model found at epoch 27 with kappa_score value: 0.8425959944725037.\n",
      "Better model found at epoch 29 with kappa_score value: 0.8433158993721008.\n",
      "Better model found at epoch 30 with kappa_score value: 0.8500062227249146.\n",
      "Better model found at epoch 33 with kappa_score value: 0.8547289371490479.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='329' class='' max='329' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [329/329 01:42<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8547289735900723\n",
      "[[679  27   2   0   6   4]\n",
      " [ 46 515  71  14   8   0]\n",
      " [  7 112 153  41  20   3]\n",
      " [ 17  20  42 138  64  26]\n",
      " [ 14   6  15  49 199  28]\n",
      " [ 15   2   3  25  83 175]]\n"
     ]
    }
   ],
   "source": [
    "fname = 'RNXT50'\n",
    "pred, target = [], []\n",
    "NFOLDS = nfolds\n",
    "for fold in range(NFOLDS):\n",
    "    print('-' * 20, 'fold:', fold, '-' * 20)\n",
    "    data = get_data(fold)\n",
    "    model = Model()\n",
    "    learn = Learner(\n",
    "        data, \n",
    "        model, \n",
    "        loss_func=nn.CrossEntropyLoss(), \n",
    "        opt_func=Over9000, \n",
    "        metrics=[KappaScore(weights='quadratic')]\n",
    "    ).to_fp16()\n",
    "    logger = CSVLogger(learn, '{}_{}/log_{}_{}'.format(MODELS, MODEL_VER, fname, fold))\n",
    "    learn.clip_grad = 1.0\n",
    "    learn.split([model.head])\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(\n",
    "        40, \n",
    "        max_lr=3e-4,\n",
    "        div_factor=100, \n",
    "        pct_start=0.0, \n",
    "        callbacks = [\n",
    "            SaveModelCallback(\n",
    "                learn, \n",
    "                name='model_{}'.format(MODEL_VER), \n",
    "                monitor='kappa_score'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    torch.save(learn.model.state_dict(), '{}_{}/{}_fold{}.pth'.format(MODELS, MODEL_VER, fname, fold))\n",
    "    learn.model.eval()\n",
    "    pred_fold, target_fold = [], []\n",
    "    with torch.no_grad():\n",
    "        for step, (x, y) in progress_bar(\n",
    "            enumerate(data.dl(DatasetType.Valid)),\n",
    "            total=len(data.dl(DatasetType.Valid))\n",
    "        ):\n",
    "            p = learn.model(*x)\n",
    "            pred_step = p.float().cpu()\n",
    "            target_step = y.cpu()\n",
    "            pred.append(pred_step)\n",
    "            target.append(target_step)\n",
    "            pred_fold.append(pred_step)\n",
    "            target_fold.append(target_step)\n",
    "    p = torch.argmax(torch.cat(pred_fold,0),1)\n",
    "    t = torch.cat(target_fold)\n",
    "    print(cohen_kappa_score(t,p,weights='quadratic'))\n",
    "    print(confusion_matrix(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8556796703062655\n",
      "[[2731  116    5    2   14    5]\n",
      " [ 233 2098  228   26   29    2]\n",
      " [  40  406  615  198   69   13]\n",
      " [  71   77  152  560  256  110]\n",
      " [  66   46   49  188  757  139]\n",
      " [  64   10   14  110  313  704]]\n"
     ]
    }
   ],
   "source": [
    "p = torch.argmax(torch.cat(pred,0),1)\n",
    "t = torch.cat(target)\n",
    "print(cohen_kappa_score(t,p,weights='quadratic'))\n",
    "print(confusion_matrix(t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3 (2 GPUs)",
   "language": "python",
   "name": "orange2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
